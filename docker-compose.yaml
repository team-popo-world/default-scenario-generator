services:
  # Airflow 전용 PostgreSQL
  postgres:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - pg_data:/var/lib/postgresql/data

  # MLflow 전용 PostgreSQL
  postgres-mlflow:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_USER: mlflowuser
      POSTGRES_PASSWORD: mlflowpassword
      POSTGRES_DB: mlflowdatabase
    volumes:
      - mlflow_pg_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U mlflowuser -d mlflowdatabase"]
      interval: 10s
      timeout: 5s
      retries: 5


  # MLflow 서버 (aws S3 사용)
  mlflow-server:
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    restart: always
    depends_on:
      postgres-mlflow:
        condition: service_healthy
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-ap-northeast-2}
    ports:
      - "5001:5000"
    command: >
      mlflow server
      --backend-store-uri postgresql://mlflowuser:mlflowpassword@postgres-mlflow:5432/mlflowdatabase
      --default-artifact-root s3://team2-mlflow-bucket/artifacts/
      --host 0.0.0.0
      --port 5000

  airflow-webserver:
    build: .
    depends_on:
      - postgres
    env_file:
      - .env
    environment:
      - AIRFLOW__WEBSERVER__WEB_SERVER_HOST=0.0.0.0
      - PYTHONPATH=/opt/airflow
    user: "${AIRFLOW_UID:-50000}"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./scenario_app:/opt/airflow/scenario_app
      - ./invest:/opt/airflow/invest
      - ./news_json_files:/opt/airflow/news_json_files
      - ./result_json_files:/opt/airflow/result_json_files
    ports:
      - "8080:8080"
    command: >
      bash -c "sleep 10 && airflow db upgrade && airflow users create --username $${AIRFLOW__WEBSERVER__DEFAULT_USER:-admin} --firstname Admin --lastname User --role Admin --email admin@example.com --password $${AIRFLOW__WEBSERVER__DEFAULT_PASSWORD:-admin} && exec airflow webserver"

  airflow-scheduler:
    build: .
    depends_on:
      - postgres
    env_file:
      - .env  
    environment:
      - PYTHONPATH=/opt/airflow
    user: "${AIRFLOW_UID:-50000}" 
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./scenario_app:/opt/airflow/scenario_app
      - ./invest:/opt/airflow/invest
      - ./news_json_files:/opt/airflow/news_json_files
      - ./result_json_files:/opt/airflow/result_json_files
    command: airflow scheduler
  
  fastapi:
    build: 
      context: .
      dockerfile: Dockerfile.fastapi
    depends_on:
      - postgres  # 필요한 경우만
    env_file:
      - .env
    # user: "${AIRFLOW_UID:-50000}"
    volumes:
      - ./invest:/opt/fastapi/invest
    ports:
      - "8002:8002"
    # command: >
    #   uvicorn invest.main_api:app --host 0.0.0.0 --port 8002 --reload

  qdrant:
    image: qdrant/qdrant:latest
    restart: always
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC API
    volumes:
      - qdrant_storage:/qdrant/storage

volumes:
  pg_data:
  qdrant_storage:
  mlflow_pg_data:

  ## 확인용 올려보기!! commit