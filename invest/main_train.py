import mlflow
import mlflow.sklearn
from invest.mlflow_config import get_mlflow_client  # ì´ import ìœ ì§€
import numpy as np
from pathlib import Path
import pandas as pd
import os

# airflow ìš© import
from invest.models.kmeans import kmeans
from invest.models.result import result
from invest.models.feature_pairs import feature_pairs

def model_train(with_id_df):
    # MLflow ì„¤ì • - mlflow_config.py ì‚¬ìš©
    mlflow_client = get_mlflow_client()
    
    # investSessionId drop : ëª¨ë¸ë§ìš© ë°ì´í„°
    df = with_id_df.drop(["userId", "investSessionId"], axis=1)

    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
    current_script_dir = Path(__file__).parent.resolve()
    
    # ì‹œê°í™”.png, ëª¨ë¸ ê²°ê³¼.pkl ì €ì¥ê²½ë¡œ ì§€ì • (í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€)
    folder_path = current_script_dir / 'models'
    folder_path.mkdir(exist_ok=True)  # í´ë” ìƒì„±

    # mlflow ì‹¤í–‰ ì´ë¦„ ì„¤ì •
    run_name = f"kmeans_clustering_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}"
    
    try:
        with mlflow.start_run(run_name=run_name):
            print(f"ğŸš€ MLflow ì‹¤í–‰ ì‹œì‘: {run_name}")
            
            # 1. ë°ì´í„° ì •ë³´ ë¡œê¹…
            data_params = {
                'data_shape': f"{df.shape[0]}x{df.shape[1]}",
                'feature_count': df.shape[1],
                'sample_count': df.shape[0],
                'feature_names': str(list(df.columns))  # ë¬¸ìì—´ë¡œ ë³€í™˜
            }
            mlflow.log_params(data_params)

            # K-means ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •
            n_clusters = 5
            init_method = 'k-means++'
            max_iter = 300
            n_init = 10
            random_state = 42

            # 2. í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…
            model_params = {
                'n_clusters': n_clusters,
                'init_method': init_method,
                'max_iter': max_iter,
                'n_init': n_init,
                'random_state': random_state,
                'algorithm': 'K-means'
            }
            mlflow.log_params(model_params)
            
            # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
            print("ğŸ“Š ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
            model, cluster_labels, clustered_df = kmeans(df, n_clusters, init_method, max_iter, n_init, random_state)

            # ëª¨ë¸ í‰ê°€ 
            print("ğŸ“ˆ ëª¨ë¸ í‰ê°€ ì¤‘...")
            silhouette_avg, inertia, cluster_sizes, cluster_centers, cluster_info_path = result(df, model, cluster_labels, folder_path)
            
            # 3. ë©”íŠ¸ë¦­ ë¡œê¹…
            metrics = {
                'silhouette_score': float(silhouette_avg),
                'inertia': float(inertia),
                'n_clusters_final': int(len(np.unique(cluster_labels)))
            }
            mlflow.log_metrics(metrics)

            # 4. í´ëŸ¬ìŠ¤í„°ë³„ í¬ê¸° ë° ë¹„ìœ¨ ë¡œê¹…
            cluster_metrics = {}
            for cluster_id, size in cluster_sizes.items():
                cluster_metrics[f"cluster_{cluster_id}_size"] = int(size)
                cluster_metrics[f"cluster_{cluster_id}_percent"] = float(size/len(df))
            
            mlflow.log_metrics(cluster_metrics)
            
            # 5. í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì  ë¡œê¹…
            center_params = {}
            for i, center in enumerate(cluster_centers):
                if len(center) >= 2:  # ìµœì†Œ 2ì°¨ì› í™•ì¸
                    center_params[f"cluster_{i}_center_x"] = float(center[0])
                    center_params[f"cluster_{i}_center_y"] = float(center[1])
                # ì „ì²´ ì¤‘ì‹¬ì  (ë¬¸ìì—´ë¡œ ë³€í™˜)
                center_params[f"cluster_{i}_center"] = str(center.tolist())
            
            mlflow.log_params(center_params)

            # 6. ëª¨ë¸ ì €ì¥
            print("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
            try:
                mlflow.sklearn.log_model(
                    model, 
                    "kmeans_model",
                    registered_model_name="investment_clustering_model"
                )
                print("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ëª¨ë¸ ë“±ë¡ ì‹¤íŒ¨, ë¡œê¹…ë§Œ ì§„í–‰: {e}")
                mlflow.sklearn.log_model(model, "kmeans_model")

            # 7. í´ëŸ¬ìŠ¤í„° ì •ë³´ íŒŒì¼ MLflowì— ì—…ë¡œë“œ
            if cluster_info_path and os.path.exists(cluster_info_path):
                mlflow.log_artifact(str(cluster_info_path), "cluster_analysis")
                print("âœ… í´ëŸ¬ìŠ¤í„° ë¶„ì„ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")

            # 8. ì‹œê°í™” ë° ì•„í‹°íŒ©íŠ¸ ì €ì¥
            print("ğŸ¨ ì‹œê°í™” ìƒì„± ì¤‘...")
            plot_path = feature_pairs(df, n_clusters, cluster_labels, model, folder_path)

            # ì‹œê°í™” íŒŒì¼ì´ ìƒì„±ë˜ì—ˆë‹¤ë©´ MLflowì— ì—…ë¡œë“œ
            if plot_path and os.path.exists(plot_path):
                mlflow.log_artifact(str(plot_path), "visualizations")
                print("âœ… ì‹œê°í™” íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")
            
            # ì¶”ê°€ë¡œ ë‹¤ë¥¸ PNG íŒŒì¼ë“¤ë„ ì—…ë¡œë“œ
            visualization_files = list(folder_path.glob("*.png"))
            
            for viz_file in visualization_files:
                if viz_file != plot_path:  # ì´ë¯¸ ì—…ë¡œë“œí•œ íŒŒì¼ì€ ì œì™¸
                    try:
                        mlflow.log_artifact(str(viz_file), "visualizations")
                    except Exception as e:
                        print(f"âš ï¸ ì‹œê°í™” íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {viz_file}, {e}")
            
            # 9. ë¡œì»¬ íŒŒì¼ ì •ë¦¬ (MLflow ì—…ë¡œë“œ í›„)
            files_to_remove = []
            if cluster_info_path:
                files_to_remove.append(cluster_info_path)
            if plot_path:
                files_to_remove.append(plot_path)
            
            # ë‹¤ë¥¸ ì‹œê°í™” íŒŒì¼ë“¤ë„ ì •ë¦¬
            files_to_remove.extend(visualization_files)
            
            for file_path in files_to_remove:
                try:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                except Exception as e:
                    print(f"âš ï¸ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {file_path}, {e}")

            # ì‹¤í–‰ ì •ë³´ ì¶œë ¥
            run_id = mlflow.active_run().info.run_id
            experiment_name = mlflow.get_experiment(mlflow.active_run().info.experiment_id).name
            
            print(f"\n=== MLflow ì‹¤í–‰ ì™„ë£Œ ===")
            print(f"ğŸ†” ì‹¤í–‰ ID: {run_id}")
            print(f"ğŸ§ª ì‹¤í—˜ ì´ë¦„: {experiment_name}")
            print(f"ğŸƒ ì‹¤í–‰ ì´ë¦„: {run_name}")
            print(f"ğŸ“Š ì‹¤ë£¨ì—£ ì ìˆ˜: {silhouette_avg:.4f}")
            print(f"ğŸ“ˆ ê´€ì„±(Inertia): {inertia:.4f}")
            print(f"ğŸ‘¥ í´ëŸ¬ìŠ¤í„°ë³„ ìƒ˜í”Œ ìˆ˜: {cluster_sizes}")
            print(f"ğŸŒ MLflow UI: http://43.203.175.69:5001")

    except Exception as e:
        print(f"âŒ MLflow ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        print(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
        # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê²°ê³¼ëŠ” ë°˜í™˜
        
    # DB ì—…ë°ì´íŠ¸ìš© df
    update_df = clustered_df[["cluster_num"]].copy()
    update_df.loc[:,"invest_session_id"] = with_id_df["investSessionId"].values
    update_df.loc[:,"user_id"] = with_id_df["userId"].values

    return update_df
